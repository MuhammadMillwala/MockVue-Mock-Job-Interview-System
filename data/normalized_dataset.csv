Questions,Answers
what is artificial intelligence,artificial intelligence is an area of computer science that emphasizes the creation of intelligent machine that work and reacts like humans
what is an artificial intelligence neural networks,artificial intelligence neural networks can model mathematically the way biological brain works allowing the machine to think and learn the same way the humans do making them capable of recognizing things like speech objects and animals like we do
give an explanation on the difference between strong ai and weak ai,strong ai makes strong claims that computers can be made to think on a level equal to humans while weak ai simply predicts that some features that are resembling to human intelligence can be incorporated to computer to make it more useful tools
mention the difference between statistical ai and classical ai,statistical ai is more concerned with inductive thought like given a set of pattern induce the trend etc while classical ai on the other hand is more concerned with deductive thought given as a set of constraints deduce a conclusion etc
which is the best way to go for game playing problem,heuristic approach is the best way to go for game playing problem as it will use the technique based on intelligent guesswork for example chess between humans and computers as it will use brute force computation looking at hundreds of thousands of positions
how is machine learning related to artificial intelligence,artificial intelligence is a technique that enables machines to mimic human behavior whereas machine learning is a subset of artificial intelligence it is the science of getting computers to act by feeding them data and letting them learn a few tricks on their own without being explicitly programmed to do so
what is qlearning,the qlearning is a reinforcement learning algorithm in which an agent tries to learn the optimal policy from its past experiences with the environment the past experiences of an agent are a sequence of stateactionrewards
what is deep learning,deep learning imitates the way our brain works ie it learns from experiences it uses the concepts of neural networks to solve complex problems
what are bayesian networks,bayesian network is a statistical model that represents a set of variables and their conditional dependencies in the form of a directed acyclic graph on the occurrence of an event bayesian networks can be used to predict the likelihood that any one of several possible known causes was the contributing factor for example a bayesian network could be used to study the relationship between diseases and symptoms given various symptoms the bayesian network is ideal for computing the probabilities of the presence of various diseases
explain the assessment that is used to test the intelligence of a machine,in artificial intelligence ai a turing test is a method of inquiry for determining whether or not a computer is capable of thinking like a human being
explain reward maximization in reinforcement learning,the rl agent works based on the theory of reward maximization this is exactly why the rl agent must be trained in such a way that he takes the best action so that the reward is maximum
what is exploitation and exploration tradeoff,an important concept in reinforcement learning is the exploration and exploitation tradeoff exploration like the name suggests is about exploring and capturing more information about an environment on the other hand exploitation is about using the already known exploited information to heighten the rewardsconsider the fox and tiger example where the fox eats only the meat small chunks close to him but he doesnt eat the bigger meat chunks at the top even though the bigger meat chunks would get him more rewards if the fox only focuses on the closest reward he will never reach the big chunks of meat this is called exploitation but if the fox decides to explore a bit it can find the bigger reward ie the big chunk of meat this is exploration
what are hyperparameters in deep neural networks,hyperparameters are variables that define the structure of the network for example variables such as the learning rate define how the network is trained they are used to define the number of hidden layers that must be present in a network more hidden units can increase the accuracy of the network whereas a lesser number of units may cause underfitting
how does data overfitting occur,overfitting occurs when a statistical model or machine learning algorithm captures the noise of the data this causes an algorithm to show low bias but high variance in the outcome
mention a technique that helps to avoid overfitting in a neural network,dropout is a type of regularization technique used to avoid overfitting in a neural network it is a technique where randomly selected neurons are dropped during training the dropout value of a network must be chosen wisely a value too low will result in a minimal effect and a value too high results in underlearning by the network
what is stemming lemmatization in nlp,stemming algorithms work by cutting off the end or the beginning of the word taking into account a list of common prefixes and suffixes that can be found in an inflected word this indiscriminate cutting can be successful on some occasions but not always lemmatization on the other hand takes into consideration the morphological analysis of the words to do so it is necessary to have detailed dictionaries which the algorithm can look through to link the form back to its lemma
how is computer vision and ai related,computer vision is a field of artificial intelligence that is used to obtain information from images or multidimensional data machine learning algorithms such as kmeans is used for image segmentation support vector machine is used for image classification and so on therefore computer vision makes use of ai technologies to solve complex problems such as object detection image processing etc
which is better for image classification supervised or unsupervised classification justify,in supervised classification the images are manually fed and interpreted by the machine learning expert to create feature classes
finite difference filters in image processing are very susceptible to noise to cope up with this which method can you use so that there would be minimal distortions by noise,image smoothing is one of the best methods used for reducing noise by forcing pixels to be more like their neighbors this reduces any distortions caused by contrasts
how is game theory and ai related,in the context of artificial intelligenceai and deep learning systems game theory is essential to enable some of the key capabilities required in multiagent environments in which different ai programs need to interact or compete in order to accomplish a goal
what is generality in ai,generality is the measure of ease with which the method can be adapted to different domains of application
what is a topdown parser,a topdown parser begins by hypothesizing a sentence and successively predicting lower level constituents until individual preterminal symbols are written
mention the difference between breadth first search and best first search in artificial intelligence,these are the two strategies which are quite similar in best first search we expand the nodes in accordance with the evaluation function while in breadth first search a node is expanded in accordance to the cost function of the parent node
what are frames and scripts in artificial intelligence,frames are a variant of semantic networks which is one of the popular ways of presenting nonprocedural knowledge in an expert system a frame which is an artificial data structure is used to divide knowledge into substructure by representing stereotyped situations scripts are similar to frames except the values that fill the slots must be ordered scripts are used in natural language understanding systems to organize a knowledge base in terms of the situation that the system should understand
what is fopl stands for and explain its role in artificial intelligence,fopl stands for first order predicate logic predicate logic provides a language to express assertions about certain world an inference system to deductive apparatus whereby we may draw conclusions from such assertion a semantic based on set theory
for online search in artificial intelligence which search agent operates by interleaving computation and action,in online search it will first take action and then observes the environment
which search algorithm will use a limited amount of memory in online search,rbfe and sma will solve any kind of problem that a cant by using a limited amount of memory
in artificial intelligence where you can use the bayes rule,in artificial intelligence to answer the probabilistic queries conditioned on one piece of evidence bayes rule can be used
for building a bayes model how many terms are required,for building a bayes model in ai three terms are required they are one conditional probability and two unconditional probability
what is the consequence between a node and its predecessors while creating bayesian network,while creating bayesian network the consequence between a node and its predecessors is that a node can be conditionally independent of its predecessors
to answer any query how the bayesian network can be used,if a bayesian network is a representative of the joint distribution then by summing all the relevant joint entries it can solve any query
what combines inductive methods with the power of first order representations,inductive logic programming combines inductive methods with the power of first order representations
in inductive logic programming what needed to be satisfied,the objective of an inductive logic programming is to come up with a set of sentences for the hypothesis such that the entailment constraint is satisfied
which algorithm inverts a complete resolution strategy,inverse resolution inverts a complete resolution as it is a complete algorithm for learning first order theories
in speech recognition what kind of signal is used,in speech recognition acoustic signal is used to identify a sequence of words
in speech recognition which model gives the probability of each word following each word,biagram model gives the probability of each word following each other word in speech recognition
what is hidden markov model hmms is used,hidden markov models are a ubiquitous tool for modelling time series data or to model sequence behaviour they are used in almost all current speech recognition systems
in hmm where does the additional variable is added,while staying within the hmm network the additional state variables can be added to a temporal model
in artificial intelligence what do semantic analyses used for,in artificial intelligence to extract the meaning from the group of sentences semantic analysis is used
what is meant by compositional semantics,the process of determining the meaning of pq from pq and is known as compositional semantics
which process makes different logical expression looks identical,unification process makes different logical expressions identical lifted inferences require finding substitute which can make a different expression looks identical this process is called unification
which is the most straight forward approach for planning algorithm,state space search is the most straight forward approach for planning algorithm because it takes account of everything for finding a solution
what do you understand by artificial intelligence,artificial intelligence is computer science technology that emphasizes creating intelligent machine that can mimic human behavior here intelligent machines can be defined as the machine that can behave like a human think like a human and also capable of decision making it is made up of two words artificial and intelligence which means the manmade thinking ability with artificial intelligence we do not need to preprogram the machine to perform a task instead we can create a machine with the programmed algorithms and it can work on its ow
why do we need artificial intelligence,the goal of artificial intelligence is to create intelligent machines that can mimic human behavior we need ai for todays world to solve complex problems make our lives more smoothly by automating the routine work saving the manpower and to perform many more other tasks
what do you understand by the reward maximization,reward maximization term is used in reinforcement learning and which is a goal of the reinforcement learning agent in rl a reward is a positive feedback by taking action for a transition from one state to another if the agent performs a good action by applying optimal policies he gets a reward and if he performs a bad action one reward is subtracted the goal of the agent is to maximize these rewards by applying optimal policies which is termed as reward maximization
what are intelligent agents and how are they used in ai,intelligent agents are autonomous entities that use sensors to know what is going on and then use actuators to perform their tasks or goals they can be simple or complex and can be programmed to learn to accomplish their jobs better
what is tensorflow and what is it used for,tensorflowis an opensource software library initially developed by the google brain team for use in machine learning and neural networks research it is used for dataflow programming tensorflow makes it much easier to build certain ai features into applications including natural language processing and speech recognition
what is machine learning and how does it relate to ai,machine learning is a subset of ai the idea is that machines will learn and get better at tasks over time rather than having humans continually having to input parameters machine learning is a practical application of ai
what are neural networks and how do they relate to ai,neural networks are a class of machine learning algorithms the neuron part of the neural is the computational component and the network part is how the neurons are connected neural networks pass data among themselves gathering more and more meaning as the data moves along because the networks are interconnected more complex data can be processed more efficiently
why is image recognition a key function of ai,humans are visual and ai is designed to emulate human brains therefore teaching machines to recognize and categorize images is a crucial part of ai image recognition also helps machines to learn as in machine learning because the more images that are processed the better the software gets at recognizing and processing those images
what is automatic programming,automatic programming is describing what a program should do and then having the ai system write the program
what are constraint satisfaction problems,constraint satisfaction problems csps are mathematical problems defined as a set of objects the state of which must meet several constraints csps are useful for ai because the regularity of their formulation offers commonality for analyzing and solving problems
what is supervised versus unsupervised learning,supervised learning is a machine learning process in which outputs are fed back into a computer for the software to learn from for more accurate results the next time with supervised learning the machine receives initial training to start in contrast unsupervised learning means a computer will learn without initial training to base its knowledge
what role does computer vision play in ai,artificial intelligence ai is broken down into a number of subfields one of which is known as computer vision computer vision is the process of teaching computers to understand and collect data from the visual environment such as graphics therefore ai technology is used by computer vision in order to address complicated challenges such as image analysis object identification and other similar issues
where does artificial intelligence go from here,it is anticipated that artificial intelligence will continue to have a significant impact on a large number of people as well as almost every sector artificial intelligence has become the primary impetus behind the development of new technologies such as robots the internet of things and large data sets ai is capable of making an ideal judgment in a split second which is almost difficult for a person to do cancer treatment cuttingedge global climate solutions smart transportation and space research are all being aided by ai we dont expect it to renounce its position as the driving force behind computer innovation and progress any time soon artificial intelligence will have a greater influence on the globe than any other technological advancement in human history
what do you comprehend by the phrase reward maximization,reinforcement learning uses the phrase reward maximization to describe the purpose of the agent which is to maximize rewards realworld rewards are positive feedback for doing an action that results in a change in a state a reward is given to the agent if he uses optimum policies to complete a good deed and a reward is deducted if he fails to do so rewards are maximized by using the best rules possible which is known as reward maximization
what is your comprehension of hyperparameters,the training process is controlled by hyperparameters model train performance is directly influenced by these factors which may be changed to ones liking they are made known in advance algorithm hyperparameters that have no influence on simulation results but can influence the efficiency and acquisition of skills are the other two categories of hyperparameters that may be inferred when accommodating the machine to the learning algorithm
what is a chatbot,a chatbot is a computer program with artificial intelligence ai that can converse with humans using natural language processing the communication may take place on a website via an application or through one of the several messaging applications these chatbots which are often referred to as digital assistants are capable of interacting with people either via the exchange of text or by voice commands the majority of companies now make extensive use of ai chatbots in order to provide roundtheclock virtual customer service to their clientele
what is the future of artificial intelligence,artificial intelligence has affected many humans and almost every industry and it is expected to continue to do so artificial intelligence has been the main driver of emerging technologies like the internet of things big data and robotics ai can harness the power of a massive amount of data and make an optimal decision in a fraction of seconds which is almost impossible for a normal human ai is leading areas that are important for mankind such as cancer research cuttingedge climate change technologies smart cars and space exploration it has taken the center stage of innovation and development of computing and it is not ceding the stage in the foreseeable future artificial intelligence is going to impact the world more than anything in the history of mankind
explain cost function,a cost function is a scalar function that helps identify how wrong an ai model is with regard to its ability to determine the relationship between x and y in other words it tells us the neural networks error factor the neural network works better when the cost function is lower for instance it takes the output predicted by the neural network and the actual output and then computes how incorrect the model was in its prediction so the cost function will give a lower number if the predictions dont differ too much from the actual values and viceversa
explain vanishing gradient,as more layers are added and the distance from the final layer increases backpropagation is not as helpful in sending information to the lower layers as a result the information is sent back and the gradients start disappearing and becoming small in relation to network weights
mention the steps of the gradient descent algorithm,the gradient descent algorithm helps in optimization and in finding coefficients of parameters that help minimize the cost function the steps that help achieve this are as follows step 1 give weights xy random values and then compute the error also called sse step 2 compute the gradient or the change in sse when you change the value of the weights xy by a small amount this step helps us identify the direction in which we must move x and y to minimize sse step 3 adjust the weights with the gradients for achieving optimal values for the minimal sse step 4 change the weights for predicting and calculating the new error step 5 repeat steps 2 and 3 till the time making more adjustments stops producing significant error reduction
what is the difference between artificial intelligence machine learning and deep learning,dl is a subset of ml which is the subset of ai hence ai is the allencompassing concept that initially erupted in computer science it was then followed by ml that thrived later and lastly dl that is now promising to escalate the advances of ai to another level
name some popular programming languages in ai,r python lisp prolog java
name some popular programming languages in ai,an expert system is an artificial intelligence program that has an expertlevel knowledge about a specific area of data and its utilisation to react appropriately these systems tend to have the capability to substitute a human expert
what is the tower of hanoi,tower of hanoi essentially is a mathematical puzzle that displays how recursion is utilised as a device in building up an algorithm to solve a specific problem the tower of hanoi can be solved using a decision tree and a breadthfirst search bfs algorithm in ai with 3 disks a puzzle can essentially be solved in 7 moves however the minimal number of moves required to solve a tower of hanoi puzzle is 2n 1 where n is the number of disks
what is an a algorithm search method,a is a computer algorithm in ai that is extensively used for the purpose of finding paths or traversing graphs to obtain the most optimal route between nodes it is widely used in solving pathfinding problems in video games considering its flexibility and versatility it can be used in a wide range of contexts a is formulated with weighted graphs which means it can find the best path involving the smallest cost in terms of distance and time this makes a an informed search algorithm for bestfirst search
what is a breadthfirst search algorithm,bfs algorithm is used to search tree or graph data structures it starts from the root node proceeds through neighbouring nodes and finally moves towards the next level of nodes till the arrangement is found and created it produces one tree at any given moment as this pursuit is capable of being executed by utilising the fifo firstin firstout data structure this strategy gives the shortest path to the solution
what is a depthfirst search algorithm,depthfirst search dfs is an algorithm that is based on lifo lastin firstout since recursion is implemented with lifo stack data structure the nodes are in a different order than in bfs the path is stored in each iteration from root to leaf nodes in a linear fashion with space requirement
what is fuzzy logic,fuzzy logic is a subset of ai it is a way of encoding human learning for artificial processing it is represented as ifthen rules
what is ensemble learning,ensemble learning is a computational technique in which classifiers or experts are strategically formed and combined it is used to improve classification prediction and function approximation of any model
explain tree topology,as the name suggests tree topology has several connected elements arranged like the branches of a tree the structure has at least three specific levels in the hierarchy these are scalable and accessible while troubleshooting and are so preferred a common drawback in this topology is the hindrance or malfunctioning of the primary node
explain karl pearsons coefficient of correlation,karl pearsons correlation coefficient is a measure of the strength of a linear association between two variables it is denoted by r or rxy where x and y are the two variables involved this method of correlation draws a line of best fit through the data of two variables
how to select the best hyperparameters in a treebased model,measure the performance over validation data
how would you describe ml to a nontechnical person,ml is geared toward pattern recognition a great example of this is your facebook newsfeed and netflixs recommendation engine in this scenario ml algorithms observe patterns and learn from them when you deploy an ml program it will keep learning and improving with each attempt
whats selection bias what other types of biases could you encounter during sampling,when youre dealing with a nonrandom sample selection bias will occur due to flaws in the selection process this happens when a subset of the data is consistently excluded because of a particular attribute this exclusion will distort results and influence the statistical significance of the test other types of biases include survivorship bias and undercoverage bias its important to always consider and reduce such biases because youll want your smart algorithms to make accurate predictions based on the data
whats an eigenvalue what about an eigenvector,the directions along which a particular linear transformation compresses flips or stretches is called eigenvalue eigenvectors are used to understand these linear transformations for example to make better sense of the covariance of the covariance matrix the eigenvector will help identify the direction in which the covariances are going the eigenvalues will express the importance of each feature eigenvalues and eigenvectors are both critical to computer vision and ml applications
would you use batch normalization if so can you explain why,the idea here is to standardize the data before sending it to another layer this approach helps reduce the impact of previous layers by keeping the mean and variance constant it also makes the layers independent of each other to achieve rapid convergence for example when we normalize features from 0 to 1 or from 1 to 100 it helps accelerate the learning cycle
when is it necessary to update an algorithm,you should update an algorithm when the underlying data source has been changed or whenever theres a case of nonstationarity the algorithm should also be updated when you want the model to evolve as data streams through the infrastructure
what would you do if data in a data set were missing or corrupted,whenever data is missing or corrupted you either replace it with another value or drop those rows and columns altogether in pandas both isnull and dropna are handy tools to find missing or corrupted data and drop those values you can also use the fillna method to fill the invalid values in a placeholderfor example 0
what is transfer learning and how does it compare to a neural architecture approach,transfer learning is a process wherein the learning from an already developed model is resued and built upon for a new task essentially it is using pretrained models and customizing them for your use case
how do you choose an algorithm for solving artificial intelligence and machine learning issues,before choosing an algorithm for solving artificial intelligence and machine learning issues i try to identify the issue completely this helps me to understand the situation to a greater extent it then allows me to determine the most suitable input and the algorithm for solving the issue completely it is necessary to choose an algorithm that is accurate scalable and simple in nature for me it is important to finish the project within the time frame so i focus on analysing the data first and then choose the algorithm accordingly depending on training and build time
what is simulated annealing algorithm,the process is of heating and cooling a metal to change its internal structure although for modifying its physical properties is known as annealing as soon as the metal cools it forms a new structure also metal is going to retain its newly obtained properties although we have to keep the variable temperature in a simulated annealing process first we have to set high temperature then left it to allow cool slowly with the proceeding algorithm further if there is high temperature algorithm accepts worse solutions with high frequency
what is natural language processing,we use english language to communicate between an intelligent system and nlp processing of natural language plays an important role in various systems
what is fuzzy logic implementation,basically it can be implemented in systems with various sizes and capabilities that should be range from mall microcontrollers to large also it can be implemented in hardware software or a combination of both in ai
what are expert systems in ai,we can say these are computer applications also with the help of this development we can solve complex problems it has level of human intelligence and expertise
give a brief introduction to robotics,basically robots have their specific aim as they manipulate the objects for example by perceiving picking moving modifying the physical properties of an object
how are artificial intelligence and machine learning different from one another,machine learning and deep learning are the subsets of artificial intelligence while ai is a smart operating system that uses the cognitiobn abilities of a human brain to solve complex problems machine learning is a computer system that allows machines to learn from the data collected by surveys among other things artificial intelligence processes are concerned with maximizing the chances of success meanwhile machine learnings main concern is accuracy and pattern not success
what are some of the popular ai domains,the answer to this artificial intelligence interview question will include machine learning neutral networks robotics expert systems fuzzy logic systems and natural language processing these popular subsets or domains of artificial intelligence have gained prominence in the last decade
which is better for image classification supervised or unsupervised classification justify,in supervised classification the images are manually fed and interpreted by the machine learning expert to create feature classes in unsupervised classification the machine learning software creates feature classes based on image pixel values therefore it is better to choose supervised classification for image classification in terms of accuracy
inite difference filters in image processing are very susceptible to noise to cope up with this which method can you use so that there would be minimal distortions by noise,image smoothing is one of the best methods used for reducing noise by forcing pixels to be more like their neighbors this reduces any distortions caused by contrasts
what is a confusion matrix how does it work,a confusion matrix is a specific table that is commonly used to measure the performance of an algorithm it is mostly used in supervised learning in unsupervised learning its called the matching matrix it has two parameters actual and predicted
